{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6e8873",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "In this lab, we will contrast regression and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0596fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from lab_utils_common import dlc, plot_data\n",
    "from plt_one_addpt_onclick import plt_one_addpt_onclick\n",
    "plt.style.use('./deeplearning.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1ec2a",
   "metadata": {},
   "source": [
    "## Classification Problems\n",
    "\n",
    "Classification can be used to solve problems like identifying whether email is Spam or Not Spam or determining if a tumor is malignant or benign. These are examples of *binary* classification where there are two possible outcomes.  Outcomes can be  described in pairs of 'positive'/'negative' such as 'yes'/'no, 'true'/'false' or '1'/'0'.\n",
    "\n",
    "Plots of classification data sets often use symbols to indicate the outcome of an example. In plots we will see in the following cells, 'X' is used to represent the positive values while 'O' represents negative outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82a6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([0., 1, 2, 3, 4, 5])\n",
    "y_train = np.array([0,  0, 0, 1, 1, 1])\n",
    "X_train2 = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_train2 = np.array([0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b00e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = y_train == 1\n",
    "neg = y_train == 0\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,3))\n",
    "#plot 1, single variable\n",
    "ax[0].scatter(x_train[pos], y_train[pos], marker='x', s=80, c = 'red', label=\"y=1\")\n",
    "ax[0].scatter(x_train[neg], y_train[neg], marker='o', s=100, label=\"y=0\", facecolors='none', \n",
    "              edgecolors=dlc[\"dlblue\"],lw=3)\n",
    "\n",
    "ax[0].set_ylim(-0.08,1.1)\n",
    "ax[0].set_ylabel('y', fontsize=12)\n",
    "ax[0].set_xlabel('x', fontsize=12)\n",
    "ax[0].set_title('one variable plot')\n",
    "ax[0].legend()\n",
    "\n",
    "#plot 2, two variables\n",
    "plot_data(X_train2, y_train2, ax[1])\n",
    "ax[1].axis([0, 4, 0, 4])\n",
    "ax[1].set_ylabel('$x_1$', fontsize=12)\n",
    "ax[1].set_xlabel('$x_0$', fontsize=12)\n",
    "ax[1].set_title('two variable plot')\n",
    "ax[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e8d29d",
   "metadata": {},
   "source": [
    "<img src=\"./images/img01.png\" style=\"width:800\"/>\n",
    "\n",
    "Note that in the above plots:\n",
    "- Positive results are shown as both a red 'X's and as y=1 in the single variable plot. Negative results are blue 'O's and are located at y=0.\n",
    "   - Recall in the case of linear regression, y would not have been limited to two values but could have been any value.\n",
    "- In the two-variable plot, the y axis is not available.  Positive results are shown as red 'X's, while negative results use the blue 'O' symbol.\n",
    "    - Recall in the case of linear regression with multiple variables, y would not have been limited to two values and a similar plot would have been three-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6017b",
   "metadata": {},
   "source": [
    "## Linear Regression approach\n",
    "Previously, we applied linear regression to build a prediction model. Inspired by that, we can try to build a model that will predict whether a tumor is benign or malignant based on tumor size.  Try the following:\n",
    "- Click on 'Run Linear Regression' to find the best linear regression model for the given data.\n",
    "    - Note the resulting linear model does **not** match the data well. \n",
    "One option to improve the results is to apply a *threshold*. \n",
    "- Tick the box on the 'Toggle 0.5 threshold' to show the predictions if a threshold is applied.\n",
    "    - These predictions look good, the predictions match the data\n",
    "- *Important*: Now, add further 'malignant' data points on the far right, in the large tumor size range (near 10), and re-run linear regression.\n",
    "    - Now, the model predicts the larger tumor, but data point at x=3 is being incorrectly predicted!\n",
    "- to clear/renew the plot, rerun the cell containing the plot command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_in = np.zeros((1))\n",
    "b_in = 0\n",
    "plt.close('all')\n",
    "addpt = plt_one_addpt_onclick( x_train,y_train, w_in, b_in, logistic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f1a51",
   "metadata": {},
   "source": [
    "<img src=\"./images/img04.png\" style=\"width:800\"/>\n",
    "\n",
    "The example above demonstrates that the linear model is insufficient to model categorical data. The model can be extended as we will discuss in the next lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed6f0d",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "In this lab we:\n",
    "- explored categorical data sets and plotting\n",
    "- determined that linear regression was insufficient for a classification problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
